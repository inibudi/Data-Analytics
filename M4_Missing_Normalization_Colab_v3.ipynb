{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rj0TMN6vOza6"
      },
      "source": [
        "# Minggu 4 — Handling Missing Values & Normalization (Colab)\n",
        "\n",
        "Tujuan: audit pola missing, lakukan imputasi sederhana & per-kelompok, lalu contoh normalisasi/standarisasi dengan anti-leakage pipeline.\n"
      ],
      "id": "Rj0TMN6vOza6"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43lUVAvxOza9"
      },
      "source": [
        "# Setup dasar\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, StandardScaler, RobustScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "print('pandas:', pd.__version__)\n"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "43lUVAvxOza9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pM5fli-TOza_"
      },
      "source": [
        "## 1) Load dataset\n",
        "Upload `contoh_simple.csv` ke `/content/datasets/`, atau notebook membuat data sintetis bila file tak ada.\n"
      ],
      "id": "pM5fli-TOza_"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOBudWBYOza_"
      },
      "source": [
        "CSV_PATH = \"/content/data/contoh_simple.csv\"  # ganti jika perlu\n",
        "os.makedirs('/content/data', exist_ok=True)\n",
        "\n",
        "if not os.path.exists(CSV_PATH):\n",
        "    print('File tidak ditemukan — membuat data sintetis untuk demo...')\n",
        "    rng = np.random.default_rng(11)\n",
        "    n = 350\n",
        "    df = pd.DataFrame({\n",
        "        'order_id': np.arange(1, n+1),\n",
        "        'shift': rng.choice(['pagi','siang','malam'], size=n),\n",
        "        'machine_speed': rng.normal(100, 13, size=n),\n",
        "        'temperature_c': rng.normal(32, 2.8, size=n),\n",
        "        'downtime_min': np.abs(rng.normal(9, 6, size=n)),\n",
        "        'is_defect': rng.choice([0,1], size=n, p=[0.9,0.1])\n",
        "    })\n",
        "    # missing untuk latihan\n",
        "    df.loc[rng.choice(df.index, 20, replace=False), 'machine_speed'] = np.nan\n",
        "    df.loc[rng.choice(df.index, 12, replace=False), 'temperature_c'] = np.nan\n",
        "    df.loc[rng.choice(df.index, 10, replace=False), 'downtime_min'] = np.nan\n",
        "    df.loc[rng.choice(df.index, 15, replace=False), 'shift'] = np.nan\n",
        "else:\n",
        "    df = pd.read_csv(CSV_PATH)\n",
        "\n",
        "df.head()\n"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "DOBudWBYOza_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01eC9unbOzbA"
      },
      "source": [
        "## 2) Audit Missing\n",
        "Cek proporsi missing per kolom dan ringkasan data.\n"
      ],
      "id": "01eC9unbOzbA"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ve78NOh4OzbB"
      },
      "source": [
        "missing_pct = df.isna().mean().sort_values(ascending=False)\n",
        "print('Missing ratio per kolom (desc):')\n",
        "print(missing_pct)\n",
        "df.describe(include='all')\n"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "ve78NOh4OzbB"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Br2QYPr8OzbC"
      },
      "source": [
        "## 3) Imputasi Sederhana (modus & median) + Per-`shift`\n"
      ],
      "id": "Br2QYPr8OzbC"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9TWv800OzbD"
      },
      "source": [
        "df_work = df.copy()\n",
        "\n",
        "# Imputasi shift (kategorik)\n",
        "if 'shift' in df_work.columns:\n",
        "    mode_val = df_work['shift'].mode(dropna=True)\n",
        "    fill_val = mode_val.iloc[0] if not mode_val.empty else 'Unknown'\n",
        "    df_work['shift'] = df_work['shift'].fillna(fill_val)\n",
        "\n",
        "# Imputasi numerik per shift (fallback median global)\n",
        "for col in ['machine_speed','temperature_c','downtime_min']:\n",
        "    if col in df_work.columns:\n",
        "        df_work[col] = pd.to_numeric(df_work[col], errors='coerce')\n",
        "        if 'shift' in df_work.columns:\n",
        "            med_by_shift = df_work.groupby('shift')[col].transform('median')\n",
        "            df_work[col] = df_work[col].fillna(med_by_shift)\n",
        "        df_work[col] = df_work[col].fillna(df_work[col].median())\n",
        "\n",
        "print('Sisa missing setelah imputasi:')\n",
        "print(df_work[['shift','machine_speed','temperature_c','downtime_min']].isna().sum())\n"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "g9TWv800OzbD"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiSeQ1OkOzbE"
      },
      "source": [
        "## 4) Simpan `interim`\n"
      ],
      "id": "MiSeQ1OkOzbE"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0wJHuqpOzbF"
      },
      "source": [
        "os.makedirs('/content/data/interim', exist_ok=True)\n",
        "interim_path = '/content/data/interim/df_imputed_week4.csv'\n",
        "df_work.to_csv(interim_path, index=False)\n",
        "interim_path\n"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "R0wJHuqpOzbF"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWHWXUIxOzbF"
      },
      "source": [
        "## 5) Normalization/Standardization + Pipeline (Anti-Leakage)\n"
      ],
      "id": "zWHWXUIxOzbF"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62pFXWg8OzbF"
      },
      "source": [
        "target = 'is_defect' if 'is_defect' in df_work.columns else None\n",
        "assert target is not None, 'Kolom target is_defect tidak ditemukan.'\n",
        "\n",
        "X = df_work.drop(columns=[target])\n",
        "y = df_work[target]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "num_cols = X_train.select_dtypes(include=['number']).columns.tolist()\n",
        "cat_cols = X_train.select_dtypes(include=['object','category','bool']).columns.tolist()\n",
        "\n",
        "# Pilih scaler: 'standard', 'minmax', atau 'robust'\n",
        "SCALER = 'standard'\n",
        "if SCALER == 'standard':\n",
        "    scaler = StandardScaler()\n",
        "elif SCALER == 'minmax':\n",
        "    scaler = MinMaxScaler()\n",
        "else:\n",
        "    scaler = RobustScaler()\n",
        "\n",
        "num_pipe = Pipeline([('imp', SimpleImputer(strategy='median')), ('sc', scaler)])\n",
        "cat_pipe = Pipeline([('imp', SimpleImputer(strategy='most_frequent')), ('oh', OneHotEncoder(handle_unknown='ignore'))])\n",
        "pre = ColumnTransformer([('num', num_pipe, num_cols), ('cat', cat_pipe, cat_cols)])\n",
        "\n",
        "clf = Pipeline([('pre', pre), ('clf', LogisticRegression(max_iter=1000))])\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "62pFXWg8OzbF"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTuwTzM6OzbG"
      },
      "source": [
        "## 6) Simpan `processed` (siap-model)\n"
      ],
      "id": "wTuwTzM6OzbG"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dslq1iD1OzbG"
      },
      "source": [
        "from sklearn import set_config\n",
        "set_config(transform_output='pandas')\n",
        "num_pipe = Pipeline([('imp', SimpleImputer(strategy='median')), ('sc', scaler)])\n",
        "cat_pipe = Pipeline([('imp', SimpleImputer(strategy='most_frequent')), ('oh', OneHotEncoder(handle_unknown='ignore', sparse_output=False))])\n",
        "pre = ColumnTransformer([('num', num_pipe, num_cols), ('cat', cat_pipe, cat_cols)])\n",
        "Xtr_ready = pre.fit_transform(X_train)\n",
        "Xte_ready = pre.transform(X_test)\n",
        "train_ready = Xtr_ready.copy(); train_ready[target] = y_train.to_numpy()\n",
        "test_ready  = Xte_ready.copy();  test_ready[target]  = y_test.to_numpy()\n",
        "os.makedirs('/content/data/processed', exist_ok=True)\n",
        "train_path = '/content/data/processed/train_ready_week4.csv'\n",
        "test_path  = '/content/data/processed/test_ready_week4.csv'\n",
        "train_ready.to_csv(train_path, index=False)\n",
        "test_ready.to_csv(test_path, index=False)\n",
        "train_path, test_path"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "dslq1iD1OzbG"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeJ0ovcyOzbH"
      },
      "source": [
        "## 7) Catatan & Tugas\n",
        "- Dokumentasikan keputusan imputasi (kolom, metode, parameter) dan scaler yang dipakai.\n",
        "- Bandingkan performa model saat `SCALER = 'standard'` vs `'minmax'` vs `'robust'` (1–2 paragraf observasi).\n",
        "- Simpan artefak `interim` & `processed` ke repositori tugas.\n"
      ],
      "id": "MeJ0ovcyOzbH"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}