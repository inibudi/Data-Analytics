{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMC-Kzru-5ni"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"Pertemuan11_Advanced_Pattern_Analysis_Real_Data.ipynb\n",
        "\n",
        "Automatically generated by Colab.\n",
        "\n",
        "**Pertemuan 11: Advanced Pattern Analysis dengan Data Real**\n",
        "Analisis Asosiasi Lanjut & Deteksi Anomali Terapan\n",
        "\"\"\"\n",
        "\n",
        "# Install required libraries\n",
        "!pip install mlxtend\n",
        "!pip install pyod\n",
        "!pip install plotly\n",
        "\n",
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ML libraries\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
        "\n",
        "# Association Rules\n",
        "from mlxtend.frequent_patterns import apriori, association_rules\n",
        "from mlxtend.preprocessing import TransactionEncoder\n",
        "\n",
        "# Anomaly Detection\n",
        "from pyod.models.knn import KNN\n",
        "from pyod.models.iforest import IForest\n",
        "from pyod.models.ocsvm import OCSVM\n",
        "\n",
        "# Visualization\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "print(\"Semua library berhasil diimport!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================\n",
        "# BAGIAN 1: UPLOAD DAN PREPROCESSING DATA\n",
        "# =============================================\n",
        "\n",
        "print(\"BAGIAN 1: UPLOAD DAN PREPROCESSING DATA\")\n",
        "print(\"=\" * 60)"
      ],
      "metadata": {
        "id": "9UBIKMI0_Keu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Langkah 1: Upload file CSV dataset\n",
        "from google.colab import files\n",
        "import io\n",
        "\n",
        "print(\"SILAHKAN UPLOAD FILE CSV DATASET:\")\n",
        "print(\"Format yang diharapkan: Member_number, Date, itemDescription\")\n",
        "print(\"Contoh format:\")\n",
        "print(\"Member_number,Date,itemDescription\")\n",
        "print(\"1808,21-07-2015,herb & pepper\")\n",
        "print(\"2552,05-01-2015,whole milk\")\n",
        "print(\"...\")\n",
        "\n",
        "# Upload file\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Cek file yang diupload\n",
        "file_name = list(uploaded.keys())[0]\n",
        "print(f\" File '{file_name}' berhasil diupload!\")\n",
        "print(f\" Size file: {len(uploaded[file_name])} bytes\")\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(io.BytesIO(uploaded[file_name]))\n",
        "\n",
        "# Tampilkan informasi dataset\n",
        "print(\"\\n INFORMASI DATASET:\")\n",
        "print(f\"Shape: {df.shape}\")\n",
        "print(f\"\\n5 Data Teratas:\")\n",
        "print(df.head())\n",
        "print(f\"\\n Info Dataset:\")\n",
        "print(df.info())\n",
        "print(f\"\\n Statistik Dataset:\")\n",
        "print(f\"Jumlah Member Unik: {df['Member_number'].nunique()}\")\n",
        "print(f\"Jumlah Item Unik: {df['itemDescription'].nunique()}\")\n",
        "print(f\"Rentang Tanggal: {df['Date'].min()} hingga {df['Date'].max()}\")"
      ],
      "metadata": {
        "id": "aPBypkGu_Sfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Langkah 2: Data Cleaning dan Preprocessing\n",
        "\n",
        "print(\"\\n DATA CLEANING DAN PREPROCESSING\")\n",
        "\n",
        "# Cek missing values\n",
        "print(\"CEK MISSING VALUES:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Handle missing values jika ada\n",
        "if df.isnull().sum().sum() > 0:\n",
        "    df = df.dropna()\n",
        "    print(\"Missing values telah dihapus\")\n",
        "\n",
        "# Konversi tanggal ke datetime\n",
        "print(\"\\n KONVERSI FORMAT TANGGAL:\")\n",
        "try:\n",
        "    df['Date'] = pd.to_datetime(df['Date'], format='%d-%m-%Y')\n",
        "    print(\"Format tanggal berhasil dikonversi\")\n",
        "except:\n",
        "    try:\n",
        "        df['Date'] = pd.to_datetime(df['Date'])\n",
        "        print(\"Format tanggal berhasil dikonversi (auto-detect)\")\n",
        "    except:\n",
        "        print(\"Gagal mengkonversi format tanggal\")\n",
        "\n",
        "print(f\"Rentang tanggal setelah konversi: {df['Date'].min()} hingga {df['Date'].max()}\")\n",
        "\n",
        "# Analisis dasar dataset\n",
        "print(\"\\n ANALISIS DASAR DATASET:\")\n",
        "print(f\"Total transaksi: {len(df)}\")\n",
        "print(f\"Jumlah member unik: {df['Member_number'].nunique()}\")\n",
        "print(f\"Jumlah item unik: {df['itemDescription'].nunique()}\")\n",
        "print(f\"Periode data: {(df['Date'].max() - df['Date'].min()).days} hari\")\n",
        "\n",
        "# Tampilkan item paling populer\n",
        "print(f\"\\n 10 ITEM PALING POPULER:\")\n",
        "top_items = df['itemDescription'].value_counts().head(10)\n",
        "print(top_items)"
      ],
      "metadata": {
        "id": "iGdOW423CUrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Langkah 3: Exploratory Data Analysis\n",
        "\n",
        "print(\"\\n EXPLORATORY DATA ANALYSIS\")\n",
        "\n",
        "# Visualisasi 1: Top 20 items paling populer\n",
        "plt.figure(figsize=(12, 8))\n",
        "top_20_items = df['itemDescription'].value_counts().head(20)\n",
        "sns.barplot(y=top_20_items.index, x=top_20_items.values, palette='viridis')\n",
        "plt.title('Top 20 Items Paling Populer')\n",
        "plt.xlabel('Jumlah Kemunculan')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Visualisasi 2: Distribusi transaksi per member\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "transactions_per_member = df.groupby('Member_number').size()\n",
        "sns.histplot(transactions_per_member, bins=50, kde=True)\n",
        "plt.title('Distribusi Jumlah Transaksi per Member')\n",
        "plt.xlabel('Jumlah Transaksi')\n",
        "plt.ylabel('Frekuensi')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "# Zoom in untuk melihat distribusi yang lebih detail\n",
        "sns.histplot(transactions_per_member[transactions_per_member <= 50], bins=30, kde=True)\n",
        "plt.title('Distribusi Jumlah Transaksi per Member (≤ 50 transaksi)')\n",
        "plt.xlabel('Jumlah Transaksi')\n",
        "plt.ylabel('Frekuensi')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Visualisasi 3: Pola waktu transaksi\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "df['year_month'] = df['Date'].dt.to_period('M')\n",
        "transactions_per_month = df.groupby('year_month').size()\n",
        "transactions_per_month.plot(kind='line', marker='o')\n",
        "plt.title('Trend Transaksi per Bulan')\n",
        "plt.xlabel('Bulan')\n",
        "plt.ylabel('Jumlah Transaksi')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "df['day_of_week'] = df['Date'].dt.day_name()\n",
        "transactions_per_day = df['day_of_week'].value_counts()\n",
        "transactions_per_day = transactions_per_day.reindex(['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'])\n",
        "transactions_per_day.plot(kind='bar', color='skyblue')\n",
        "plt.title('Transaksi per Hari dalam Seminggu')\n",
        "plt.xlabel('Hari')\n",
        "plt.ylabel('Jumlah Transaksi')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "df['month'] = df['Date'].dt.month_name()\n",
        "transactions_per_month_name = df['month'].value_counts()\n",
        "transactions_per_month_name = transactions_per_month_name.reindex(['January', 'February', 'March', 'April', 'May', 'June',\n",
        "                                                                   'July', 'August', 'September', 'October', 'November', 'December'])\n",
        "transactions_per_month_name.plot(kind='bar', color='lightcoral')\n",
        "plt.title('Transaksi per Bulan')\n",
        "plt.xlabel('Bulan')\n",
        "plt.ylabel('Jumlah Transaksi')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"STATISTIK TRANSAKSI:\")\n",
        "print(f\"Rata-rata transaksi per member: {transactions_per_member.mean():.2f}\")\n",
        "print(f\"Median transaksi per member: {transactions_per_member.median()}\")\n",
        "print(f\"Std dev transaksi per member: {transactions_per_member.std():.2f}\")\n",
        "print(f\"Member paling aktif: {transactions_per_member.idxmax()} dengan {transactions_per_member.max()} transaksi\")"
      ],
      "metadata": {
        "id": "Vh-6C0zmCcpn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================\n",
        "# BAGIAN 2: ADVANCED ASSOCIATION RULES\n",
        "# =============================================\n",
        "\n",
        "print(\"\\n BAGIAN 2: ADVANCED ASSOCIATION RULES ANALYSIS\")\n",
        "print(\"=\" * 60)"
      ],
      "metadata": {
        "id": "b_OSYUWKCl-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Langkah 4: Persiapan Data untuk Association Rules\n",
        "\n",
        "print(\"PERSIAPAN DATA UNTUK ASSOCIATION RULES\")\n",
        "\n",
        "# Group by Member_number dan Date untuk mendapatkan transaksi\n",
        "# Asumsikan setiap kombinasi Member_number + Date adalah satu transaksi\n",
        "df['Transaction_ID'] = df['Member_number'].astype(str) + '_' + df['Date'].astype(str)\n",
        "\n",
        "print(f\"Jumlah transaksi unik: {df['Transaction_ID'].nunique()}\")\n",
        "\n",
        "# Group items by transaction\n",
        "transactions = df.groupby('Transaction_ID')['itemDescription'].apply(list).tolist()\n",
        "\n",
        "print(f\"Contoh 3 transaksi pertama:\")\n",
        "for i, transaction in enumerate(transactions[:3]):\n",
        "    print(f\"Transaksi {i+1}: {transaction}\")\n",
        "\n",
        "# Encode transactions\n",
        "te = TransactionEncoder()\n",
        "te_array = te.fit(transactions).transform(transactions)\n",
        "df_encoded = pd.DataFrame(te_array, columns=te.columns_)\n",
        "\n",
        "print(f\"\\n DATA BERHASIL DIENCODE\")\n",
        "print(f\"Shape data encoded: {df_encoded.shape}\")\n",
        "print(f\"Jumlah item unik: {len(df_encoded.columns)}\")\n",
        "\n",
        "# Hitung support untuk setiap item\n",
        "item_support = df_encoded.mean().sort_values(ascending=False)\n",
        "print(f\"\\n SUPPORT TOP 15 ITEMS:\")\n",
        "print(item_support.head(15))"
      ],
      "metadata": {
        "id": "QCXzwAq2Cn__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Langkah 5: Advanced Association Rules Analysis\n",
        "\n",
        "print(\"\\n ADVANCED ASSOCIATION RULES ANALYSIS\")\n",
        "\n",
        "# Tentukan parameter yang optimal berdasarkan karakteristik data\n",
        "total_transactions = len(transactions)\n",
        "print(f\"Total transaksi: {total_transactions}\")\n",
        "\n",
        "# Hitung min_support yang reasonable (item harus muncul setidaknya 50 kali)\n",
        "min_support = 50 / total_transactions\n",
        "print(f\"Minimum support yang digunakan: {min_support:.4f}\")\n",
        "\n",
        "# Cari frequent itemsets\n",
        "frequent_itemsets = apriori(df_encoded,\n",
        "                           min_support=min_support,\n",
        "                           use_colnames=True,\n",
        "                           max_len=4)\n",
        "\n",
        "print(f\" FREQUENT ITEMSETS DITEMUKAN: {len(frequent_itemsets)}\")\n",
        "\n",
        "if len(frequent_itemsets) > 0:\n",
        "    # Generate rules dengan confidence yang reasonable\n",
        "    rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.1)\n",
        "\n",
        "    print(f\" TOTAL RULES AWAL: {len(rules)}\")\n",
        "\n",
        "    # Tambahkan advanced metrics\n",
        "    rules['conviction'] = (1 - rules['consequent support']) / (1 - rules['confidence'])\n",
        "    rules['leverage'] = rules['support'] - (rules['antecedent support'] * rules['consequent support'])\n",
        "    rules['jaccard'] = rules['support'] / (rules['antecedent support'] + rules['consequent support'] - rules['support'])\n",
        "\n",
        "    # Hitung composite score\n",
        "    rules['composite_score'] = (\n",
        "        rules['lift'] * 0.4 +\n",
        "        rules['confidence'] * 0.3 +\n",
        "        np.log1p(rules['support'] * 100) * 0.2 +\n",
        "        rules['conviction'] * 0.1\n",
        "    )\n",
        "\n",
        "    # Filter rules yang meaningful\n",
        "    meaningful_rules = rules[\n",
        "        (rules['lift'] > 1.2) &\n",
        "        (rules['confidence'] > 0.3) &\n",
        "        (rules['conviction'] > 1) &\n",
        "        (rules['support'] > min_support * 2)  # Minimum 2x min_support\n",
        "    ].copy()\n",
        "\n",
        "    print(f\"MEANINGFUL RULES: {len(meaningful_rules)}\")\n",
        "\n",
        "    if len(meaningful_rules) > 0:\n",
        "        # Tampilkan top rules\n",
        "        top_rules = meaningful_rules.nlargest(20, 'composite_score')\n",
        "\n",
        "        print(f\"\\n TOP 20 ASSOCIATION RULES:\")\n",
        "        print(\"=\" * 90)\n",
        "        for idx, row in top_rules.iterrows():\n",
        "            antecedents = list(row['antecedents'])\n",
        "            consequents = list(row['consequents'])\n",
        "            print(f\"Rule {idx+1:2d}: {antecedents} → {consequents}\")\n",
        "            print(f\"        Support: {row['support']:.4f} | Confidence: {row['confidence']:.3f} | Lift: {row['lift']:.3f}\")\n",
        "            print(f\"        Conviction: {row['conviction']:.3f} | Composite: {row['composite_score']:.3f}\")\n",
        "            print(\"-\" * 70)\n",
        "    else:\n",
        "        print(\"Tidak ada meaningful rules yang memenuhi kriteria\")\n",
        "        # Tampilkan rules terbaik meski tidak memenuhi semua kriteria\n",
        "        if len(rules) > 0:\n",
        "            best_rules = rules.nlargest(10, 'composite_score')\n",
        "            print(f\"\\n BEST AVAILABLE RULES:\")\n",
        "            for idx, row in best_rules.iterrows():\n",
        "                antecedents = list(row['antecedents'])\n",
        "                consequents = list(row['consequents'])\n",
        "                print(f\"Rule {idx+1}: {antecedents} → {consequents}\")\n",
        "                print(f\"        Support: {row['support']:.4f} | Confidence: {row['confidence']:.3f} | Lift: {row['lift']:.3f}\")\n",
        "else:\n",
        "    print(\"Tidak ada frequent itemsets yang ditemukan\")\n",
        "    print(\"Coba turunkan minimum support\")"
      ],
      "metadata": {
        "id": "4IRWSS6dCuDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Langkah 6: Visualisasi Association Rules\n",
        "\n",
        "print(\"\\n VISUALISASI ASSOCIATION RULES\")\n",
        "\n",
        "if 'meaningful_rules' in locals() and len(meaningful_rules) > 0:\n",
        "    # Prepare data untuk visualisasi\n",
        "    viz_rules = meaningful_rules.nlargest(15, 'composite_score')\n",
        "\n",
        "    # Buat label untuk rules\n",
        "    rule_labels = []\n",
        "    for _, row in viz_rules.iterrows():\n",
        "        ant = list(row['antecedents'])\n",
        "        cons = list(row['consequents'])\n",
        "        # Batasi panjang label\n",
        "        ant_str = ', '.join(ant[:2]) + ('...' if len(ant) > 2 else '')\n",
        "        cons_str = ', '.join(cons[:2]) + ('...' if len(cons) > 2 else '')\n",
        "        label = f\"{ant_str} → {cons_str}\"\n",
        "        rule_labels.append(label)\n",
        "\n",
        "    # Visualisasi 1: Bubble Chart\n",
        "    plt.figure(figsize=(14, 8))\n",
        "    scatter = plt.scatter(\n",
        "        viz_rules['support'],\n",
        "        viz_rules['confidence'],\n",
        "        s=viz_rules['lift'] * 50,  # Size berdasarkan lift\n",
        "        c=viz_rules['conviction'],   # Color berdasarkan conviction\n",
        "        cmap='RdYlGn',\n",
        "        alpha=0.7,\n",
        "        edgecolors='black',\n",
        "        linewidth=0.5\n",
        "    )\n",
        "\n",
        "    plt.colorbar(scatter, label='Conviction')\n",
        "    plt.xlabel('Support')\n",
        "    plt.ylabel('Confidence')\n",
        "    plt.title('Association Rules: Support vs Confidence\\n(Size = Lift, Color = Conviction)')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    # Annotate beberapa rules teratas\n",
        "    for i, (x, y, label) in enumerate(zip(viz_rules['support'], viz_rules['confidence'], rule_labels)):\n",
        "        if i < 5:  # Hanya annotate 5 teratas\n",
        "            plt.annotate(label, (x, y), xytext=(5, 5), textcoords='offset points',\n",
        "                        fontsize=9, bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.7))\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Visualisasi 2: Horizontal bar chart untuk composite score\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    y_pos = range(len(viz_rules))\n",
        "    plt.barh(y_pos, viz_rules['composite_score'])\n",
        "    plt.yticks(y_pos, rule_labels)\n",
        "    plt.xlabel('Composite Score')\n",
        "    plt.title('Top Association Rules by Composite Score')\n",
        "    plt.grid(True, axis='x', alpha=0.3)\n",
        "\n",
        "    # Tambahkan nilai pada bars\n",
        "    for i, v in enumerate(viz_rules['composite_score']):\n",
        "        plt.text(v + 0.01, i, f'{v:.2f}', va='center', fontsize=9)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Visualisasi 3: Network graph sederhana\n",
        "    print(\"\\n NETWORK ANALYSIS:\")\n",
        "    # Analisis items yang paling sering muncul dalam rules\n",
        "    all_items_in_rules = []\n",
        "    for _, row in meaningful_rules.iterrows():\n",
        "        all_items_in_rules.extend(list(row['antecedents']))\n",
        "        all_items_in_rules.extend(list(row['consequents']))\n",
        "\n",
        "    item_freq_in_rules = pd.Series(all_items_in_rules).value_counts()\n",
        "    print(\"Items paling sering muncul dalam rules:\")\n",
        "    print(item_freq_in_rules.head(10))\n",
        "\n",
        "else:\n",
        "    print(\"Tidak ada meaningful rules untuk divisualisasikan\")"
      ],
      "metadata": {
        "id": "aczaWwChC4Ov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================\n",
        "# BAGIAN 3: ANOMALY DETECTION PADA DATA TRANSAKSI\n",
        "# =============================================\n",
        "\n",
        "print(\"\\n BAGIAN 3: ANOMALY DETECTION PADA DATA TRANSAKSI\")\n",
        "print(\"=\" * 60)"
      ],
      "metadata": {
        "id": "CQjb4W5TDErI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Langkah 7: Feature Engineering untuk Anomaly Detection\n",
        "\n",
        "print(\"FEATURE ENGINEERING UNTUK ANOMALY DETECTION\")\n",
        "\n",
        "# Buat features berdasarkan perilaku member\n",
        "member_features = []\n",
        "\n",
        "for member_id in df['Member_number'].unique():\n",
        "    member_data = df[df['Member_number'] == member_id]\n",
        "\n",
        "    features = {\n",
        "        'member_id': member_id,\n",
        "        'total_transactions': len(member_data),\n",
        "        'unique_items': member_data['itemDescription'].nunique(),\n",
        "        'transaction_days': member_data['Date'].nunique(),\n",
        "        'avg_items_per_transaction': len(member_data) / member_data['Date'].nunique() if member_data['Date'].nunique() > 0 else 0,\n",
        "        'transaction_frequency': (member_data['Date'].max() - member_data['Date'].min()).days / len(member_data) if len(member_data) > 1 else 0,\n",
        "        'prefers_weekend': (member_data['day_of_week'].isin(['Saturday', 'Sunday']).sum() / len(member_data)),\n",
        "        'most_common_item_count': member_data['itemDescription'].value_counts().iloc[0] if len(member_data) > 0 else 0,\n",
        "        'entropy': -sum((member_data['itemDescription'].value_counts() / len(member_data)) *\n",
        "                       np.log(member_data['itemDescription'].value_counts() / len(member_data))) if len(member_data) > 0 else 0\n",
        "    }\n",
        "\n",
        "    member_features.append(features)\n",
        "\n",
        "# Convert ke DataFrame\n",
        "df_member_features = pd.DataFrame(member_features)\n",
        "\n",
        "print(f\" FEATURES BERHASIL DIBUAT UNTUK {len(df_member_features)} MEMBER\")\n",
        "print(f\"Features yang tersedia: {list(df_member_features.columns)}\")\n",
        "print(f\"\\n STATISTIK FEATURES:\")\n",
        "print(df_member_features.describe())\n",
        "\n",
        "# Visualisasi distribusi features\n",
        "fig, axes = plt.subplots(3, 3, figsize=(15, 12))\n",
        "features_to_plot = ['total_transactions', 'unique_items', 'transaction_days',\n",
        "                   'avg_items_per_transaction', 'transaction_frequency',\n",
        "                   'prefers_weekend', 'most_common_item_count', 'entropy']\n",
        "\n",
        "for idx, feature in enumerate(features_to_plot):\n",
        "    if idx < 9:  # Pastikan tidak melebihi subplot yang tersedia\n",
        "        row, col = idx // 3, idx % 3\n",
        "        axes[row, col].hist(df_member_features[feature], bins=30, alpha=0.7, color='skyblue')\n",
        "        axes[row, col].set_title(f'Distribution of {feature}')\n",
        "        axes[row, col].set_xlabel(feature)\n",
        "        axes[row, col].set_ylabel('Frequency')\n",
        "        axes[row, col].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kw562ya5DHL_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Langkah 8: Ensemble Anomaly Detection pada Member Behavior\n",
        "\n",
        "print(\"ENSEMBLE ANOMALY DETECTION\")\n",
        "\n",
        "# Pilih features untuk anomaly detection (exclude member_id)\n",
        "feature_columns = [col for col in df_member_features.columns if col != 'member_id']\n",
        "X = df_member_features[feature_columns]\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "print(f\" FEATURES BERHASIL DI-SCALING\")\n",
        "print(f\"Shape data: {X_scaled.shape}\")\n",
        "\n",
        "# Inisialisasi multiple anomaly detection models\n",
        "models = {\n",
        "    'Isolation Forest': IForest(contamination=0.05, random_state=42),\n",
        "    'KNN': KNN(contamination=0.05),\n",
        "    'One-Class SVM': OCSVM(contamination=0.05)\n",
        "}\n",
        "\n",
        "# Train models dan collect predictions\n",
        "ensemble_predictions = {}\n",
        "ensemble_scores = {}\n",
        "\n",
        "print(\"TRAINING ENSEMBLE MODELS...\")\n",
        "for name, model in models.items():\n",
        "    model.fit(X_scaled)\n",
        "\n",
        "    # Predictions dan scores\n",
        "    y_pred = model.predict(X_scaled)\n",
        "    y_scores = model.decision_function(X_scaled)\n",
        "\n",
        "    ensemble_predictions[name] = y_pred\n",
        "    ensemble_scores[name] = y_scores\n",
        "\n",
        "    # Hitung jumlah anomali yang terdeteksi\n",
        "    n_anomalies = sum(y_pred)\n",
        "    print(f\"   {name}: {n_anomalies} anomali terdeteksi ({n_anomalies/len(y_pred)*100:.1f}%)\")\n",
        "\n",
        "# Ensemble voting (majority vote)\n",
        "ensemble_df = pd.DataFrame(ensemble_predictions)\n",
        "ensemble_vote = (ensemble_df.sum(axis=1) >= 2).astype(int)  # Minimal 2 dari 3 model setuju\n",
        "\n",
        "# Ensemble weighted by scores\n",
        "scores_df = pd.DataFrame(ensemble_scores)\n",
        "# Normalize scores to 0-1 range\n",
        "normalized_scores = (scores_df - scores_df.min()) / (scores_df.max() - scores_df.min())\n",
        "weighted_scores = normalized_scores.mean(axis=1)\n",
        "# Use 95th percentile sebagai threshold\n",
        "ensemble_weighted = (weighted_scores > weighted_scores.quantile(0.95)).astype(int)\n",
        "\n",
        "print(f\"\\n ENSEMBLE RESULTS:\")\n",
        "print(f\"Majority Voting: {sum(ensemble_vote)} anomali terdeteksi\")\n",
        "print(f\"Weighted Score: {sum(ensemble_weighted)} anomali terdeteksi\")\n",
        "\n",
        "# Tambahkan results ke dataframe\n",
        "df_member_features['anomaly_vote'] = ensemble_vote\n",
        "df_member_features['anomaly_weighted'] = ensemble_weighted\n",
        "df_member_features['anomaly_score'] = weighted_scores\n",
        "\n",
        "# Identifikasi member yang terdeteksi sebagai anomali\n",
        "anomalous_members_vote = df_member_features[df_member_features['anomaly_vote'] == 1]\n",
        "anomalous_members_weighted = df_member_features[df_member_features['anomaly_weighted'] == 1]\n",
        "\n",
        "print(f\"\\n MEMBER YANG TERDETEKSI SEBAGAI ANOMALI:\")\n",
        "print(\"Majority Voting Ensemble:\")\n",
        "print(anomalous_members_vote[['member_id', 'total_transactions', 'unique_items', 'anomaly_score']].head(10))\n",
        "\n",
        "print(\"\\nWeighted Score Ensemble:\")\n",
        "print(anomalous_members_weighted[['member_id', 'total_transactions', 'unique_items', 'anomaly_score']].head(10))"
      ],
      "metadata": {
        "id": "h2OWRt4nDOjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Langkah 9: Analisis dan Interpretasi Anomali\n",
        "\n",
        "print(\"\\n ANALISIS DAN INTERPRETASI ANOMALI\")\n",
        "\n",
        "# Bandingkan karakteristik member normal vs anomali\n",
        "normal_members = df_member_features[df_member_features['anomaly_vote'] == 0]\n",
        "anomalous_members = df_member_features[df_member_features['anomaly_vote'] == 1]\n",
        "\n",
        "print(\"PERBANDINGAN KARAKTERISTIK: NORMAL vs ANOMALI\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "for feature in ['total_transactions', 'unique_items', 'transaction_days', 'avg_items_per_transaction']:\n",
        "    normal_mean = normal_members[feature].mean()\n",
        "    anomaly_mean = anomalous_members[feature].mean()\n",
        "\n",
        "    print(f\"{feature}:\")\n",
        "    print(f\"  • Normal: {normal_mean:.2f}\")\n",
        "    print(f\"  • Anomali: {anomaly_mean:.2f}\")\n",
        "    print(f\"  • Rasio: {anomaly_mean/normal_mean:.2f}x\")\n",
        "    print()\n",
        "\n",
        "# Visualisasi perbandingan\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "comparison_features = ['total_transactions', 'unique_items', 'transaction_days', 'avg_items_per_transaction']\n",
        "\n",
        "for idx, feature in enumerate(comparison_features):\n",
        "    row, col = idx // 2, idx % 2\n",
        "\n",
        "    # Boxplot comparison\n",
        "    data_to_plot = [normal_members[feature], anomalous_members[feature]]\n",
        "    axes[row, col].boxplot(data_to_plot, labels=['Normal', 'Anomali'])\n",
        "    axes[row, col].set_title(f'Perbandingan {feature}')\n",
        "    axes[row, col].set_ylabel(feature)\n",
        "    axes[row, col].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Analisis detail member anomali\n",
        "print(\"\\n ANALISIS DETAIL MEMBER ANOMALI:\")\n",
        "if len(anomalous_members) > 0:\n",
        "    for idx, row in anomalous_members.head(5).iterrows():\n",
        "        member_id = row['member_id']\n",
        "        member_data = df[df['Member_number'] == member_id]\n",
        "\n",
        "        print(f\"\\n MEMBER {member_id} (Anomaly Score: {row['anomaly_score']:.3f}):\")\n",
        "        print(f\"   • Total Transaksi: {row['total_transactions']}\")\n",
        "        print(f\"   • Unique Items: {row['unique_items']}\")\n",
        "        print(f\"   • Transaction Days: {row['transaction_days']}\")\n",
        "        print(f\"   • Avg Items/Transaction: {row['avg_items_per_transaction']:.2f}\")\n",
        "\n",
        "        # Analisis pola pembelian\n",
        "        top_items = member_data['itemDescription'].value_counts().head(5)\n",
        "        print(f\"   • Top 5 Items: {list(top_items.index)}\")\n",
        "        print(f\"   • Rentang Tanggal: {member_data['Date'].min()} hingga {member_data['Date'].max()}\")"
      ],
      "metadata": {
        "id": "k-lfX-kmDWKr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Langkah 10: Business Recommendations dan Export Results\n",
        "\n",
        "print(\"\\n BUSINESS RECOMMENDATIONS DAN EXPORT RESULTS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Business Recommendations berdasarkan analysis\n",
        "print(\"BUSINESS RECOMMENDATIONS:\")\n",
        "print(\"\\n1.  ASSOCIATION RULES OPTIMIZATION:\")\n",
        "if 'meaningful_rules' in locals() and len(meaningful_rules) > 0:\n",
        "    best_rule = meaningful_rules.nlargest(1, 'composite_score').iloc[0]\n",
        "    antecedents = list(best_rule['antecedents'])\n",
        "    consequents = list(best_rule['consequents'])\n",
        "\n",
        "    print(f\"   • BUNDLING STRATEGY: Gabungkan {antecedents} dengan {consequents}\")\n",
        "    print(f\"     (Confidence: {best_rule['confidence']:.1%}, Lift: {best_rule['lift']:.1f}x)\")\n",
        "\n",
        "    # Rekomendasi berdasarkan support dan confidence\n",
        "    high_support_rules = meaningful_rules[meaningful_rules['support'] > meaningful_rules['support'].quantile(0.75)]\n",
        "    if len(high_support_rules) > 0:\n",
        "        print(f\"   • STORE LAYOUT: Prioritaskan {len(high_support_rules)} rules dengan support tinggi\")\n",
        "\n",
        "    high_confidence_rules = meaningful_rules[meaningful_rules['confidence'] > 0.5]\n",
        "    if len(high_confidence_rules) > 0:\n",
        "        print(f\"   • PROMOTION: Gunakan {len(high_confidence_rules)} rules dengan confidence > 50%\")\n",
        "else:\n",
        "    print(\"   • Tidak ada rules kuat yang ditemukan untuk rekomendasi spesifik\")\n",
        "\n",
        "print(\"\\n2.  ANOMALY DETECTION INSIGHTS:\")\n",
        "print(f\"   • {len(anomalous_members)} member terdeteksi sebagai anomali ({len(anomalous_members)/len(df_member_features)*100:.1f}%)\")\n",
        "print(f\"   • Fokus investigasi pada member dengan anomaly score > {anomalous_members['anomaly_score'].quantile(0.75):.3f}\")\n",
        "\n",
        "if len(anomalous_members) > 0:\n",
        "    # Analisis tipe anomali\n",
        "    high_transaction_anomalies = anomalous_members[anomalous_members['total_transactions'] > anomalous_members['total_transactions'].quantile(0.75)]\n",
        "    low_transaction_anomalies = anomalous_members[anomalous_members['total_transactions'] < anomalous_members['total_transactions'].quantile(0.25)]\n",
        "\n",
        "    print(f\"   • {len(high_transaction_anomalies)} member dengan transaksi sangat tinggi\")\n",
        "    print(f\"   • {len(low_transaction_anomalies)} member dengan transaksi sangat rendah\")\n",
        "\n",
        "print(\"\\n3.  MONITORING & ACTION PLAN:\")\n",
        "print(\"   • Implementasi real-time association rules analysis\")\n",
        "print(\"   • Dashboard monitoring untuk member behavior anomalies\")\n",
        "print(\"   • Regular review dan update model (monthly)\")\n",
        "print(\"   • Integration dengan CRM untuk personalized marketing\")\n",
        "\n",
        "# Export results\n",
        "print(\"\\n EXPORTING RESULTS...\")\n",
        "\n",
        "# Export association rules jika ada\n",
        "if 'meaningful_rules' in locals() and len(meaningful_rules) > 0:\n",
        "    rules_export = meaningful_rules[['antecedents', 'consequents', 'support', 'confidence', 'lift', 'conviction', 'composite_score']].copy()\n",
        "    # Convert itemsets to string untuk export\n",
        "    rules_export['antecedents'] = rules_export['antecedents'].apply(lambda x: ', '.join(list(x)))\n",
        "    rules_export['consequents'] = rules_export['consequents'].apply(lambda x: ', '.join(list(x)))\n",
        "    rules_export.to_csv('association_rules_results.csv', index=False)\n",
        "    print(\"Association rules exported ke 'association_rules_results.csv'\")\n",
        "    files.download('association_rules_results.csv') # Move download inside the conditional block\n",
        "\n",
        "# Export anomaly detection results\n",
        "anomaly_export = df_member_features[['member_id', 'total_transactions', 'unique_items', 'transaction_days',\n",
        "                                    'avg_items_per_transaction', 'anomaly_vote', 'anomaly_weighted', 'anomaly_score']]\n",
        "anomaly_export.to_csv('anomaly_detection_results.csv', index=False)\n",
        "print(\"Anomaly detection results exported ke 'anomaly_detection_results.csv'\")\n",
        "\n",
        "# Download files\n",
        "files.download('anomaly_detection_results.csv')\n",
        "\n",
        "print(\"\\n ANALISIS SELESAI!\")\n",
        "print(\"File results telah didownload:\")\n",
        "if 'meaningful_rules' in locals() and len(meaningful_rules) > 0:\n",
        "    print(\"   - association_rules_results.csv\")\n",
        "print(\"   - anomaly_detection_results.csv\")"
      ],
      "metadata": {
        "id": "-qcayj0cDfjr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}