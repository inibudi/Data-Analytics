{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Minggu 3 — Data Cleaning & Preprocessing (Colab, v2)\n",
        "\n",
        "Perubahan utama:\n",
        "- **Imputasi eksplisit** untuk kolom:\n",
        "  - `shift` (kategorik) → modus atau label `'Unknown'`\n",
        "  - `machine_speed`, `temperature_c`, `downtime_min` (numerik) → median\n",
        "- Dua level hasil:\n",
        "  1) `df_clean_min.csv` (dedup by-features + imputasi sederhana pada kolom target)\n",
        "  2) `train_ready.csv` & `test_ready.csv` (via pipeline: imputasi + One-Hot + scaling; **tanpa kebocoran**)\n",
        "\n",
        "Catatan: tetap pertahankan **raw** apa adanya; simpan hasil ke `data/interim/` dan `data/processed/`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ⬇️ Setup dasar\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import os\n",
        "\n",
        "pd.options.display.max_columns = 200"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Load data\n",
        "Opsi:\n",
        "1. Upload manual ke `/content/datasets/` → set `CSV_PATH`\n",
        "2. Gunakan Drive\n",
        "3. Jika tidak ada, buat data sintetis untuk demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "CSV_PATH = \"/content/datasets/contoh.csv\"  # ganti jika perlu\n",
        "os.makedirs('/content/datasets', exist_ok=True)\n",
        "\n",
        "if not os.path.exists(CSV_PATH):\n",
        "    print(\"File tidak ditemukan, membuat data sintetis untuk demo...\")\n",
        "    rng = np.random.default_rng(42)\n",
        "    n = 500\n",
        "    df = pd.DataFrame({\n",
        "        'order_id': np.arange(1, n+1),\n",
        "        'shift': rng.choice(['pagi','siang','malam'], size=n),\n",
        "        'machine_speed': rng.normal(100, 15, size=n),\n",
        "        'temperature_c': rng.normal(32, 3, size=n),\n",
        "        'downtime_min': np.abs(rng.normal(10, 8, size=n)),\n",
        "        'is_defect': rng.choice([0,1], size=n, p=[0.85,0.15])\n",
        "    })\n",
        "    # Missing & outlier\n",
        "    df.loc[rng.choice(df.index, 20, replace=False), 'machine_speed'] = np.nan\n",
        "    df.loc[rng.choice(df.index, 10, replace=False), 'shift'] = np.nan\n",
        "    df.loc[rng.choice(df.index, 5, replace=False), 'temperature_c'] = df['temperature_c'].mean() + 6*df['temperature_c'].std()\n",
        "else:\n",
        "    df = pd.read_csv(CSV_PATH)\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Cast tipe & ringkas missing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cast tipe ringkas\n",
        "if 'shift' in df.columns:\n",
        "    df['shift'] = df['shift'].astype('category')\n",
        "\n",
        "missing_before = df.isna().mean().sort_values(ascending=False)\n",
        "print(\"Missing ratio BEFORE:\\n\", missing_before)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Dedup by-features (opsional)\n",
        "Anggap baris duplikat jika **semua fitur selain `order_id` sama**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "feature_cols = [c for c in df.columns if c.lower() != 'order_id']\n",
        "\n",
        "# Stabilkan numerik untuk dedup (opsional)\n",
        "df_tmp = df.copy()\n",
        "for c in feature_cols:\n",
        "    if pd.api.types.is_numeric_dtype(df_tmp[c]):\n",
        "        df_tmp[c] = df_tmp[c].round(6)\n",
        "\n",
        "rows_before = len(df_tmp)\n",
        "df_tmp = df_tmp.drop_duplicates(subset=feature_cols, keep='first')\n",
        "print(\"Dedup by-features — dropped:\", rows_before - len(df_tmp))\n",
        "\n",
        "# lanjutkan dengan df_dedup sebagai basis imputasi sederhana\n",
        "df_dedup = df_tmp.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Imputasi sederhana pada kolom target\n",
        "- `shift` → modus (kalau semua NaN, fallback `'Unknown'`)\n",
        "- `machine_speed`, `temperature_c`, `downtime_min` → median\n",
        "\n",
        "Ini menghasilkan **`df_clean_min.csv`** (hasil minimal yang bisa dipakai untuk EDA struktural)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_clean_min = df_dedup.copy()\n",
        "\n",
        "# Imputasi shift (kategorik)\n",
        "if 'shift' in df_clean_min.columns:\n",
        "    mode_val = df_clean_min['shift'].mode(dropna=True)\n",
        "    fill_val = mode_val.iloc[0] if not mode_val.empty else 'Unknown'\n",
        "    df_clean_min['shift'] = df_clean_min['shift'].cat.add_categories(['Unknown']) if hasattr(df_clean_min['shift'], 'cat') else df_clean_min['shift']\n",
        "    df_clean_min['shift'] = df_clean_min['shift'].fillna(fill_val)\n",
        "\n",
        "# Imputasi numerik (median)\n",
        "for col in ['machine_speed', 'temperature_c', 'downtime_min']:\n",
        "    if col in df_clean_min.columns:\n",
        "        median_val = df_clean_min[col].median(skipna=True)\n",
        "        df_clean_min[col] = pd.to_numeric(df_clean_min[col], errors='coerce')\n",
        "        df_clean_min[col] = df_clean_min[col].fillna(median_val)\n",
        "\n",
        "missing_after_min = df_clean_min.isna().mean().sort_values(ascending=False)\n",
        "print(\"Missing ratio AFTER (df_clean_min):\\n\", missing_after_min)\n",
        "\n",
        "os.makedirs('/content/data/interim', exist_ok=True)\n",
        "min_path = '/content/data/interim/df_clean_min.csv'\n",
        "df_clean_min.to_csv(min_path, index=False)\n",
        "min_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Pipeline siap-model (tanpa kebocoran)\n",
        "Split train/test dulu, lalu lakukan **imputasi + encoding + scaling** di pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "target = 'is_defect' if 'is_defect' in df.columns else None\n",
        "if target is None:\n",
        "    raise ValueError(\"Kolom target 'is_defect' tidak ditemukan. Silakan set target sesuai dataset Anda.\")\n",
        "\n",
        "X = df_dedup.drop(columns=[target])\n",
        "y = df_dedup[target]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "num_features = [c for c in X_train.select_dtypes(include=['number']).columns if c != target]\n",
        "cat_features = X_train.select_dtypes(include=['object','category','bool']).columns.tolist()\n",
        "\n",
        "from sklearn import set_config\n",
        "set_config(transform_output=\"pandas\")\n",
        "\n",
        "numeric_pipeline = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "categorical_pipeline = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "preprocess = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_pipeline, num_features),\n",
        "        ('cat', categorical_pipeline, cat_features)\n",
        "    ]\n",
        ")\n",
        "clf = Pipeline(steps=[('preprocess', preprocess), ('model', LogisticRegression(max_iter=1000))])\n",
        "clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Materialisasi dataset siap-model\n",
        "X_train_ready = clf.named_steps['preprocess'].fit_transform(X_train)\n",
        "X_test_ready  = clf.named_steps['preprocess'].transform(X_test)\n",
        "\n",
        "train_ready = X_train_ready.copy(); train_ready[target] = y_train.to_numpy()\n",
        "test_ready  = X_test_ready.copy();  test_ready[target]  = y_test.to_numpy()\n",
        "\n",
        "os.makedirs('/content/data/processed', exist_ok=True)\n",
        "train_path = '/content/data/processed/train_ready.csv'\n",
        "test_path  = '/content/data/processed/test_ready.csv'\n",
        "train_ready.to_csv(train_path, index=False)\n",
        "test_ready.to_csv(test_path, index=False)\n",
        "train_path, test_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Ringkasan\n",
        "- `df_clean_min.csv` (interim): dedup by-features + imputasi sederhana pada kolom target\n",
        "- `train_ready.csv` & `test_ready.csv` (processed): **siap-model** via pipeline (imputasi + One-Hot + scaling) tanpa kebocoran\n",
        "- Semua perubahan bisa dicatat di **cleaning_log** dan **data_dictionary**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "M3_Cleaning_Preprocessing_Colab_v2.ipynb"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}